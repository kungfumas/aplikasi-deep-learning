{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kungfumas/aplikasi-deep-learning/blob/master/Copy_of_gradio_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0729087-a6b3-4be0-a5c1-328ee8719aa4",
      "metadata": {
        "id": "e0729087-a6b3-4be0-a5c1-328ee8719aa4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vanderbilt-data-science/ai-summer-gradio/blob/main/gradio-demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Gradio for Hugging Face\n",
        "\n",
        "Hugging Face is an excellent platform to build and share your AI and ML models. One of the best ways to share the models you develop is by creating interactive web-based applications. These applications not only allow you to share your work with others who might be working on similar problems or those without a technical background, but building these applications also help you test your models and better understand how they work.\n",
        "\n",
        "Creating such web-based applications has traditionally been difficult since it required knowledge of how to host applications on the web, in addition to the various programming languages needed to build the applications from the ground up like HTML, CSS and Java.\n",
        "\n",
        "Gradio elimiates the need to know how to program in these other languages. In addtion, the integration with Hugging Face spaces allows you to host your application on the web, for free - in just a few lines of code!\n",
        "\n",
        "Today, we'll cover some of the major components of Gradio. Several parts of this session today are inspired by the Hugging Face course on Gradio available here: [Gradio Hugging Face Course](https://www.gradio.app/getting_started/)\n",
        "\n",
        "So let's get started! The first step is to install Gradio. This can be done using a simple pip install on your local machine. Since we'll be using Google Colab today, we will also need to install it here."
      ],
      "metadata": {
        "id": "PSMMc_Hj3nJQ"
      },
      "id": "PSMMc_Hj3nJQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8af6e7-420f-401b-ab3a-ac62d300cd40",
      "metadata": {
        "id": "ec8af6e7-420f-401b-ab3a-ac62d300cd40",
        "outputId": "f4d02d15-2301-451c-a50e-38c59ee85c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install transformers\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before jumping into the details, let's take a look at a simple Hello World application. This application takes in a name, and returns a greeting:"
      ],
      "metadata": {
        "id": "tsazCkaP6KCI"
      },
      "id": "tsazCkaP6KCI"
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "SBwehX4T3L-E",
        "outputId": "67a8fd50-f315-4cdb-ad07-c5b966f633d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "id": "SBwehX4T3L-E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a5f877652226e370d5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a5f877652226e370d5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you can see that it was extremely simple to create this application. It does not take much more effort to link these application to your models or any other functions. The gradio application will show up either in a pop-up, or within the Jupyter Notebook. The application is also available in your browser at the provided localhost website.\n",
        "\n",
        "\n",
        "Now, let's examine the **Interface** class. The interface class is the foundation of Gradio applications and is comprised of only 3 elements:\n",
        "\n",
        "1. fn: This can be nearly any function, and gradio can simply wrap it in an interface.\n",
        "2. inputs: The components to use for the inputs to your application.\n",
        "3. outputs: The components to use for the outputs to your application.\n",
        "\n",
        "The inputs and outputs can be of several different types. These can either be passed as objects or as their string shortcuts. In the example above, we passed \"text\" as the inputs. This is the string shortcut to the \"textbox\" type of input. Gradio refers to these as Components. You can see examples of the different types of components at the following link: [Gradio Components](https://www.gradio.app/docs/#components)\n",
        "\n",
        "Gradio **Components Attributes** allow you change change the way UI components look or behave. Let's take a look at the Hello World example above. We're currently using the string shortcut for textboxes at the moment. We can explicitly use the **Textbox** class to customize the size of the input space. We can also provide either a hint for the input required, using the placeholder parameter."
      ],
      "metadata": {
        "id": "Yk2Uj-aT_w_Q"
      },
      "id": "Yk2Uj-aT_w_Q"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox(label = \"Name\", lines=2, placeholder=\"Name Here...\"),\n",
        "    outputs=gr.Textbox(label = \"Greeting\"),\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "v7De96ymDJyi"
      },
      "id": "v7De96ymDJyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see that the space provided in the input text box is larger, and there is a prompt to indicate the type of input required. Let's take this a step further.\n",
        "\n",
        "## Multiple Inputs and Examples\n",
        "\n",
        "In the code chunk below, I modify the greet function to take in two additional parameters - isMorning and temperature. I can modify the output to say \"Good Morning or \"Good Evening\", and provide the temperature for the day. The function also returns the temperature provided in Celsius.\n",
        "\n",
        "In addition to providing prompts within the input spaces, we can also provide users with examples in a table format using the examples element in the Interface class."
      ],
      "metadata": {
        "id": "XItrB25NjAuP"
      },
      "id": "XItrB25NjAuP"
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name, isMorning, temperature):\n",
        "    salutation = \"Good morning\" if isMorning else \"Good evening\"\n",
        "    greeting = \"%s %s. It is %s degrees today\" % (salutation, name, temperature)\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[gr.Textbox(lines=2, placeholder=\"Your Name Here...\"), gr.Checkbox(label=\"Is it Morning?\"), gr.Slider(0, 100)],\n",
        "    outputs=[gr.Textbox(label = \"Greeting\"), gr.Number(label = \"Temperature in Celsius\")],\n",
        "    examples=[\n",
        "        [\"Umang\", True, 65],\n",
        "        [\"Jesse\", False, 95]]\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "bYx07WmokUiR"
      },
      "id": "bYx07WmokUiR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Class Exercise\n",
        "\n",
        "Now that we've seen the power of Gradio's component attributes, let's practice using some of them.\n",
        "\n",
        "We will use a modified version of the greet function above. Now, the greeting has options for morning, evening and afternoon. We additionally also have the ability to add a descriptor for the weather, and as before, we can indicate the temperature. Try the following:\n",
        "\n",
        "1. Use the \"[Radio](https://www.gradio.app/docs/#radio)\" class to provide UI options for choosing whether it's morning, afternoon or evening. **Pass a list of options to the choices parameter**.\n",
        "\n",
        "2. Instead of a slider, use the [Number](https://www.gradio.app/docs/#number) class to allow users to type in a number in Farenheit for the temperature.\n",
        "\n",
        "3. Use the \"[Dropdown](https://www.gradio.app/docs/#dropdown)\" class to provide UI options for choosing the weather (rainy, sunny, windy etc.). **Pass a list of options to the choices parameter**.\n",
        "\n",
        "3. Add a few examples to help users use your application!\n",
        "\n",
        "Let's take 10 minutes to work on this in breakout groups. We'll come back and discuss the answers!"
      ],
      "metadata": {
        "id": "9gSXKcDBlUUL"
      },
      "id": "9gSXKcDBlUUL"
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name, time_of_day, temperature, weather):\n",
        "    if time_of_day == \"morning\":\n",
        "      salutation = \"Good morning\"\n",
        "    elif time_of_day == \"afternoon\":\n",
        "      salutation = \"Good afternoon\"\n",
        "    elif time_of_day == \"evening\":\n",
        "      salutation = \"Good evening\"\n",
        "\n",
        "    greeting = \"%s %s! It is %s degrees today. The weather is %s.\" % (salutation, name, temperature, weather)\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)"
      ],
      "metadata": {
        "id": "S27DajYfkg4u"
      },
      "id": "S27DajYfkg4u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greet(\"Umang\", \"morning\", 65, \"rainy\")"
      ],
      "metadata": {
        "id": "9wLpj9oUrecR"
      },
      "id": "9wLpj9oUrecR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get stuck, one possible solution is in the hidden code chunk below:"
      ],
      "metadata": {
        "id": "DYnD1p0hxTdT"
      },
      "id": "DYnD1p0hxTdT"
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs= [gr.Textbox(label = \"Name\", lines=2, placeholder=\"Your Name Here...\"),\n",
        "             gr.Radio(label = \"Time of Day\", choices = [\"morning\", \"afternoon\", \"evening\"]),\n",
        "             gr.Number(label = \"Temperature\"),\n",
        "             gr.Dropdown(label = \"Weather\", choices = [\"rainy\", \"sunny\", \"windy\"]),],\n",
        "    outputs=[gr.Textbox(label = \"Greeting\"), gr.Number(label = \"Temperature in Celsius\")],\n",
        "    examples=[\n",
        "        [\"Umang\", \"morning\", 65, \"rainy\"],\n",
        "        [\"Jesse\", \"afternoon\", 87, \"sunny\"],\n",
        "        [\"Charreau\", \"evening\", 72, \"windy\"]]\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "xB2uDaC1s2Um",
        "cellView": "form"
      },
      "id": "xB2uDaC1s2Um",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So as we can see, Gradio is very customizable and intuitive. You simply wrap the components in a list. Each component in the inputs list corresponds to one of the parameters of the function, in order. Each component in the outputs list corresponds to one of the values returned by the function, again in order. The key thing to remember here is that **order matters**.\n",
        "\n",
        "Now, let's take a look at some other data types that Gradio supports. Over the next few weeks, we'll be working with text, audio, images and traditional structured data. We'll go through examples of each type below. Here, we'll use some out-of-the-box functions to demonstrate each data type in action.\n",
        "\n",
        "## Images\n",
        "\n",
        "In the code chunk below, we have a function called sepia, which takes in an image and returns the same image, but in sepia instead."
      ],
      "metadata": {
        "id": "v5D5vuw3wsEG"
      },
      "id": "v5D5vuw3wsEG"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def sepia(input_img):\n",
        "    sepia_filter = np.array(\n",
        "        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n",
        "    )\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn = sepia,\n",
        "    inputs = gr.Image(shape=(200, 200)),\n",
        "    outputs = \"image\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "flynaWDRs7BM"
      },
      "id": "flynaWDRs7BM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also instead use the built-in webcam to capture an image instead of uploading images. This can be very useful when building public facing model demos."
      ],
      "metadata": {
        "id": "mJPg7vrsy6n8"
      },
      "id": "mJPg7vrsy6n8"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=sepia,\n",
        "    live=True, #indicates a live interface\n",
        "    inputs=gr.Image(label=\"Input Image\", source=\"webcam\"),\n",
        "    outputs=\"image\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "JVX13YWMzGJb"
      },
      "id": "JVX13YWMzGJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the built in shortcuts instead of specifying the image source explicitly but just typing \"webcam\" as the inputs."
      ],
      "metadata": {
        "id": "qURDAEVW2RaJ"
      },
      "id": "qURDAEVW2RaJ"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=sepia,\n",
        "    live=True, #indicates a live interface\n",
        "    inputs=\"webcam\",\n",
        "    outputs=\"image\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "EWFBGwDn2Kj3"
      },
      "id": "EWFBGwDn2Kj3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio\n",
        "\n",
        "In the below example, we use a function that generates an audio file based on the note and the duration of the audio provided."
      ],
      "metadata": {
        "id": "1DaUINBC08X7"
      },
      "id": "1DaUINBC08X7"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "\n",
        "def generate_tone(note, octave, duration):\n",
        "    sr = 48000\n",
        "    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n",
        "    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n",
        "    duration = int(duration)\n",
        "    audio = np.linspace(0, duration, duration * sr)\n",
        "    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n",
        "    return sr, audio\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    generate_tone,\n",
        "    [\n",
        "        gr.Dropdown(notes, type=\"index\"),\n",
        "        gr.Slider(4, 6, step=1),\n",
        "        gr.Number(value=1,label=\"Duration in seconds\"),\n",
        "    ],\n",
        "    \"audio\",\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "9WDEk7cvzP9D"
      },
      "id": "9WDEk7cvzP9D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this next example, we can provide an audio as the input, and return the same audio, but reversed."
      ],
      "metadata": {
        "id": "V9OJj8if1n3p"
      },
      "id": "V9OJj8if1n3p"
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_audio(audio):\n",
        "    sr, data = audio\n",
        "    return (sr, np.flipud(data))\n",
        "\n",
        "demo = gr.Interface(fn=reverse_audio,\n",
        "                    inputs=\"microphone\",\n",
        "                    outputs=\"audio\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "f0SShrpE1nbq"
      },
      "id": "f0SShrpE1nbq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets and Files\n",
        "\n",
        "For this last example, let's see how we can use tabular data in a Gradio application. First, let's see how a row filtering function works in Gradio:"
      ],
      "metadata": {
        "id": "qse0eIPr2cuq"
      },
      "id": "qse0eIPr2cuq"
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_records(records, gender):\n",
        "    return records[records[\"gender\"] == gender]\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    filter_records,\n",
        "    [\n",
        "        gr.Dataframe(\n",
        "            headers=[\"name\", \"age\", \"gender\"],\n",
        "            datatype=[\"str\", \"number\", \"str\"],\n",
        "            row_count=5,\n",
        "            col_count=(3, \"fixed\")\n",
        "        ),\n",
        "        gr.Dropdown([\"M\", \"F\", \"O\"]),\n",
        "    ],\n",
        "    \"dataframe\",\n",
        "    description=\"Enter gender as 'M', 'F', or 'O' for other.\",\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "tdENHs0110zf"
      },
      "id": "tdENHs0110zf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also upload files to Gradio applications as below. In this demo, we input two files and the application returns a zip file containing both inputs."
      ],
      "metadata": {
        "id": "OV52xKzM3gfR"
      },
      "id": "OV52xKzM3gfR"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def zip_two_files(file1, file2):\n",
        "    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n",
        "        zipObj.write(file1.name, \"file1\")\n",
        "        zipObj.write(file2.name, \"file2\")\n",
        "    return \"tmp.zip\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    zip_two_files,\n",
        "    [\"file\", \"file\"],\n",
        "    \"file\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "emf2TfuF3cEv"
      },
      "id": "emf2TfuF3cEv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flagging and Debugging\n",
        "\n",
        "Underneath the output interfaces, there is a \"Flag\" button. When a user testing your model sees input with interesting output, such as erroneous or unexpected model behaviour, they can flag the input for the interface creator to review. Within the directory provided by the flagging_dir= argument to the Interface constructor, a CSV file will log the flagged inputs. If the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well."
      ],
      "metadata": {
        "id": "f-LQdain3yjk"
      },
      "id": "f-LQdain3yjk"
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name, isMorning, temperature):\n",
        "    salutation = \"Good morning\" if isMorning else \"Good evening\"\n",
        "    greeting = \"%s %s. It is %s degrees today\" % (salutation, name, temperature)\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[gr.Textbox(lines=2, placeholder=\"Your Name Here...\"), gr.Checkbox(label=\"Is it Morning?\"), gr.Slider(0, 100)],\n",
        "    outputs=[gr.Textbox(label = \"Greeting\"), gr.Number(label = \"Temperature in Celsius\")],\n",
        "    examples=[\n",
        "        [\"Umang\", True, 65],\n",
        "        [\"Jesse\", False, 95]]\n",
        ")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "TM44G3XB3umY"
      },
      "id": "TM44G3XB3umY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blocks: Greater Customizability over your UIs\n",
        "\n",
        "Blocks allows you to do things like: group together related demos, change where components appear on the page, handle complex data flows (e.g. outputs can serve as inputs to other functions), and update properties/visibility of components based on user interaction -- still all in Python.\n",
        "\n",
        "As an example, Blocks uses nested 'with' statements in Python to lay out components on a page.\n"
      ],
      "metadata": {
        "id": "RZkWghlp4t7e"
      },
      "id": "RZkWghlp4t7e"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def update(name):\n",
        "    return f\"Welcome to Gradio, {name}!\"\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # Hello World!\n",
        "    Start typing below to see the output.\n",
        "    \"\"\")\n",
        "    inp = gr.Textbox(placeholder=\"What is your name?\")\n",
        "    out = gr.Textbox()\n",
        "\n",
        "    inp.change(fn=update,\n",
        "               inputs=inp,\n",
        "               outputs=out)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "8-ebW9KY65hN"
      },
      "id": "8-ebW9KY65hN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This simple example introduces 5 concepts that underlie Blocks:\n",
        "\n",
        "1. Blocks allow you to build web applications that combine markdown, HTML, buttons, and interactive components simply by instantiating objects in Python inside of a \"with gradio.Blocks\" context. The order in which you instantiate components matters as each element gets rendered into the web app in the order it was created. (More complex layouts are discussed below)\n",
        "\n",
        "2. You can define regular Python functions anywhere in your code and run them with user input using BLocks. In our example, we have a simple function that adds a welcome message before a user's name, but you can write any Python function, from a simple calculation to large machine learning model's inference.\n",
        "\n",
        "3. You can assign events to any Blocks component. This will run your function when the component is clicked/changed/etc. When you assign an event, you pass in three parameters: fn: the function that should be called, inputs: the (list) of input component(s), and outputs: the (list) of output components that should be called.\n",
        "\n",
        "In this example, we run the update() function when the value in the Textbox named inp changes. The event reads the value in inp, passes it as the name parameter to update(), which then returns a value that gets assigned to our second Textbox named out.\n",
        "\n",
        "To see a list of events that each component supports, see the documentation.\n",
        "\n",
        "4. Blocks automatically figures out whether a component should be interactive (accept user input) or not, based on the event triggers you define. In our example, the first textbox is interactive, since its value is used by the update() function. The second textbox is not interactive, since its value is never used as an input. In some cases, you might want to override this, which you can do by passing the appropriate boolean to interactive, a parameter that every component accepts.\n",
        "\n",
        "5. You can write and launch() your Blocks anywhere: jupyter notebooks, colab notebooks, or regular Python IDEs since Gradio uses the standard Python interpreter. You can also share Blocks with other people by setting a single parameter: launch(share=True), which we will discuss towards the end of this guide."
      ],
      "metadata": {
        "id": "l_29-xaN72lj"
      },
      "id": "l_29-xaN72lj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, Blocks renders the components that you create vertically in one column. You can change that by creating additional columns (with gradio.Column():) or rows (with gradio.Row():) and creating components within those contexts."
      ],
      "metadata": {
        "id": "d4ukEjQq-8cv"
      },
      "id": "d4ukEjQq-8cv"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "def flip_text(x):\n",
        "    return x[::-1]\n",
        "\n",
        "def flip_image(x):\n",
        "    return np.fliplr(x)\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"Flip text or image files using this demo.\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Flip Text\"):\n",
        "            text_input = gr.Textbox()\n",
        "            text_output = gr.Textbox()\n",
        "            text_button = gr.Button(\"Flip\")\n",
        "        with gr.TabItem(\"Flip Image\"):\n",
        "            with gr.Row():\n",
        "                image_input = gr.Image()\n",
        "                image_output = gr.Image()\n",
        "            image_button = gr.Button(\"Flip\")\n",
        "\n",
        "    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n",
        "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "VZESHoTt-9YB"
      },
      "id": "VZESHoTt-9YB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multistep Demos**\n",
        "\n",
        "In some cases, you might want want a \"multi-step\" demo, in which you reuse the output of one function as the input to the next. This is really easy to do with Blocks, as you can use a component for the input of one event trigger but the output of another. Take a look at the text component in the example below, its value is the result of a speech-to-text model, but also gets passed into a sentiment analysis model:"
      ],
      "metadata": {
        "id": "aqRJja0P_P7i"
      },
      "id": "aqRJja0P_P7i"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n",
        "classifier = pipeline(\"text-classification\")\n",
        "\n",
        "def speech_to_text(speech):\n",
        "    text = asr(speech)[\"text\"]\n",
        "    return text\n",
        "\n",
        "def text_to_sentiment(text):\n",
        "    return classifier(text)[0][\"label\"]\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    audio_file = gr.Audio(type=\"filepath\")\n",
        "    text = gr.Textbox()\n",
        "    label = gr.Label()\n",
        "\n",
        "    b1 = gr.Button(\"Recognize Speech\")\n",
        "    b2 = gr.Button(\"Classify Sentiment\")\n",
        "\n",
        "    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n",
        "    b2.click(text_to_sentiment, inputs=text, outputs=label)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "fW8iqXdE_SCb"
      },
      "id": "fW8iqXdE_SCb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Updating Component Properties**\n",
        "\n",
        "So far, we have seen how to create events to update the value of another component. But if you want to change other properties of a component (like the visibility of a textbox or the choices in a radio button group)? You can do this by returning a component class's update() method instead of a regular return value from your function."
      ],
      "metadata": {
        "id": "as2lWtjD_fvR"
      },
      "id": "as2lWtjD_fvR"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def change_textbox(choice):\n",
        "    if choice == \"short\":\n",
        "        return gr.Textbox.update(lines=2, visible=True)\n",
        "    elif choice == \"long\":\n",
        "        return gr.Textbox.update(lines=8, visible=True)\n",
        "    else:\n",
        "        return gr.Textbox.update(visible=False)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    radio = gr.Radio(\n",
        "        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n",
        "    )\n",
        "    text = gr.Textbox(lines=2, interactive=True)\n",
        "\n",
        "    radio.change(fn=change_textbox, inputs=radio, outputs=text)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "c0t6ew5p_hJT"
      },
      "id": "c0t6ew5p_hJT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sharing Demos\n",
        "\n",
        "It is very easy to create demos that you can share with anyone. Simply set the \"share\" parameter to True in the demo launch() command, and Gradio will create a public link to your application. The processing for this happens locally, so your computer must stay on for the duration of others using your application. Sharing links expire after 72 hours."
      ],
      "metadata": {
        "id": "KJ7P_RAv5_8i"
      },
      "id": "KJ7P_RAv5_8i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio + Hugging Face\n",
        "\n",
        "Now that we have a good understanding of how to make Gradio applications, let's take a look at how we can use models we make or find on Hugging Face, instead of functions.\n",
        "\n",
        "Let's take a look at how we can use the default text-generation model in Hugging Face (GPT-2) to create a text-generation application.\n",
        "\n",
        "First, we use the pipeline function from the transformers library to create a function called predict, which returns the output of the model based on an input prompt."
      ],
      "metadata": {
        "id": "QcqKx_EU8LGV"
      },
      "id": "QcqKx_EU8LGV"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model = pipeline(\"text-generation\")\n",
        "\n",
        "\n",
        "def predict(prompt):\n",
        "    completion = model(prompt)[0][\"generated_text\"]\n",
        "    return completion"
      ],
      "metadata": {
        "id": "ltB9shta5DEa"
      },
      "id": "ltB9shta5DEa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to understand what we can expect this function to return, let's try the following:"
      ],
      "metadata": {
        "id": "U7150Jvd9IJB"
      },
      "id": "U7150Jvd9IJB"
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"My favorite novel is\")"
      ],
      "metadata": {
        "id": "Nr4LPWgt83s0"
      },
      "id": "Nr4LPWgt83s0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can create a Gradio application, just like before!"
      ],
      "metadata": {
        "id": "rHxBlSMB9Za2"
      },
      "id": "rHxBlSMB9Za2"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "woBLDa1c9Gsd"
      },
      "id": "woBLDa1c9Gsd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's it! Using the pipeline function, you can create an application for any model on Hugging Face!"
      ],
      "metadata": {
        "id": "RValhhSY-QiQ"
      },
      "id": "RValhhSY-QiQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Since the acquisition of Gradio by Hugging Face, there is now an even simpler way of using models on the Hugging Face hub using the **Interface.load()** command. You can simply pass the name and the organization of the model you want to use like so: \"huggingface/organization/model\""
      ],
      "metadata": {
        "id": "RhUKe30I2688"
      },
      "id": "RhUKe30I2688"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface.load(\n",
        "    \"huggingface/deepset/roberta-base-squad2\",\n",
        "    inputs = [gr.Textbox(label = \"Question\"), gr.Textbox(label = \"Context\")],\n",
        "    outputs = [gr.Textbox(label = \"Answer\"), gr.Number(label = \"Confidence\")]\n",
        ")\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "#Which name is also used to describe the Amazon rainforest in English?\n",
        "#The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species."
      ],
      "metadata": {
        "id": "wWc1yf5q9iDe"
      },
      "id": "wWc1yf5q9iDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can also load existing demos from Hugging Face spaces, by instead typing the following in the Interface.load() command: spaces/organization/space"
      ],
      "metadata": {
        "id": "Dh_5qoalAzdX"
      },
      "id": "Dh_5qoalAzdX"
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface.load(\n",
        "    \"spaces/multimodalart/latentdiffusion\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "GICzzZGy_oIm"
      },
      "id": "GICzzZGy_oIm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the above Gradio app looks similar to what we have been working on, but it seems a little more polished.\n",
        "\n",
        "To add additional content to your demo, the Interface class supports some optional parameters:\n",
        "\n",
        "*   title: you can give a title to your demo, which appears above the input and output components.\n",
        "*   description: you can give a description (in text, Markdown, or HTML) for the interface, which appears above the input and output components and below the title.\n",
        "*   article: you can also write an expanded article (in text, Markdown, or HTML) explaining the interface. If provided, it appears below the input and output components.\n",
        "*   theme: don’t like the default colors? Set the theme to use one of default, huggingface, grass, peach. You can also add the dark- prefix, e.g. dark-peach for dark theme (or just dark for the default dark theme).\n",
        "\n",
        "See the chunk below for how to add this information to our Hello World example:"
      ],
      "metadata": {
        "id": "Pis6V9UQBlQl"
      },
      "id": "Pis6V9UQBlQl"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name, time_of_day, temperature, weather):\n",
        "    if time_of_day == \"morning\":\n",
        "      salutation = \"Good morning\"\n",
        "    elif time_of_day == \"afternoon\":\n",
        "      salutation = \"Good afternoon\"\n",
        "    elif time_of_day == \"evening\":\n",
        "      salutation = \"Good evening\"\n",
        "\n",
        "    greeting = \"%s %s! It is %s degrees today. The weather is %s.\" % (salutation, name, temperature, weather)\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "\n",
        "title = \"Hello World!\"\n",
        "\n",
        "description = \"\"\"\n",
        "A simple Hello World application that takes in inputs and returns a greeting.\n",
        "\"\"\"\n",
        "\n",
        "article = \"Check out more documentation at https://www.gradio.app/getting_started/#getting_started\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs= [gr.Textbox(label = \"Name\", lines=2, placeholder=\"Your Name Here...\"),\n",
        "             gr.Radio(label = \"Time of Day\", choices = [\"morning\", \"afternoon\", \"evening\"]),\n",
        "             gr.Number(label = \"Temperature\"),\n",
        "             gr.Dropdown(label = \"Weather\", choices = [\"rainy\", \"sunny\", \"windy\"]),],\n",
        "    outputs=[gr.Textbox(label = \"Greeting\"), gr.Number(label = \"Temperature in Celsius\")],\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        "    examples=[\n",
        "        [\"Umang\", \"morning\", 65, \"rainy\"],\n",
        "        [\"Jesse\", \"afternoon\", 87, \"sunny\"],\n",
        "        [\"Charreau\", \"evening\", 72, \"windy\"]]\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "XU414nTbBgkT"
      },
      "id": "XU414nTbBgkT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}